{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb8cd3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('../dataset/stroke.csv')\n",
    "\n",
    "# Drop kolom id\n",
    "if 'id' in df.columns:\n",
    "    df.drop('id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56f3b94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop baris dengan smoking_status unknown\n",
    "df = df[df['smoking_status'] != 'Unknown']\n",
    "\n",
    "# Isi nilai kosong di 'bmi' dengan rata-rata berdasarkan gender\n",
    "df['bmi'] = df.groupby('gender')['bmi'].transform(lambda x: x.fillna(x.mean()))\n",
    "\n",
    "# Encode kolom kategorikal\n",
    "for col in ['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status']:\n",
    "    df[col] = LabelEncoder().fit_transform(df[col])\n",
    "\n",
    "# Pisahkan fitur dan target\n",
    "X = df.drop('stroke', axis=1)\n",
    "y = df['stroke']\n",
    "\n",
    "# Normalisasi\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Bagi data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae0bf017",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lenovo\\Downloads\\capstone\\.venv\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6529 - loss: 0.6229 - val_accuracy: 0.9510 - val_loss: 0.1968\n",
      "Epoch 2/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9416 - loss: 0.2141 - val_accuracy: 0.9510 - val_loss: 0.1731\n",
      "Epoch 3/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9439 - loss: 0.1828 - val_accuracy: 0.9510 - val_loss: 0.1690\n",
      "Epoch 4/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9477 - loss: 0.1706 - val_accuracy: 0.9510 - val_loss: 0.1691\n",
      "Epoch 5/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9450 - loss: 0.1882 - val_accuracy: 0.9510 - val_loss: 0.1673\n",
      "Epoch 6/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9486 - loss: 0.1645 - val_accuracy: 0.9510 - val_loss: 0.1677\n",
      "Epoch 7/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9433 - loss: 0.1765 - val_accuracy: 0.9510 - val_loss: 0.1651\n",
      "Epoch 8/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9448 - loss: 0.1652 - val_accuracy: 0.9510 - val_loss: 0.1673\n",
      "Epoch 9/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9427 - loss: 0.1675 - val_accuracy: 0.9510 - val_loss: 0.1652\n",
      "Epoch 10/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9387 - loss: 0.1793 - val_accuracy: 0.9510 - val_loss: 0.1651\n",
      "Epoch 11/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9418 - loss: 0.1713 - val_accuracy: 0.9510 - val_loss: 0.1665\n",
      "Epoch 12/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9440 - loss: 0.1655 - val_accuracy: 0.9510 - val_loss: 0.1660\n",
      "Epoch 13/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9418 - loss: 0.1678 - val_accuracy: 0.9510 - val_loss: 0.1658\n",
      "Epoch 14/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9396 - loss: 0.1746 - val_accuracy: 0.9510 - val_loss: 0.1659\n",
      "Epoch 15/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9442 - loss: 0.1703 - val_accuracy: 0.9510 - val_loss: 0.1653\n",
      "Epoch 16/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9435 - loss: 0.1630 - val_accuracy: 0.9510 - val_loss: 0.1662\n",
      "Epoch 17/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9421 - loss: 0.1640 - val_accuracy: 0.9510 - val_loss: 0.1650\n",
      "Epoch 18/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9413 - loss: 0.1572 - val_accuracy: 0.9510 - val_loss: 0.1657\n",
      "Epoch 19/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9445 - loss: 0.1626 - val_accuracy: 0.9440 - val_loss: 0.1719\n",
      "Epoch 20/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9440 - loss: 0.1749 - val_accuracy: 0.9510 - val_loss: 0.1671\n",
      "Epoch 21/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9463 - loss: 0.1579 - val_accuracy: 0.9510 - val_loss: 0.1670\n",
      "Epoch 22/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9436 - loss: 0.1597 - val_accuracy: 0.9510 - val_loss: 0.1672\n",
      "Epoch 23/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9421 - loss: 0.1674 - val_accuracy: 0.9510 - val_loss: 0.1678\n",
      "Epoch 24/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9429 - loss: 0.1627 - val_accuracy: 0.9492 - val_loss: 0.1722\n",
      "Epoch 25/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9501 - loss: 0.1505 - val_accuracy: 0.9510 - val_loss: 0.1706\n",
      "Epoch 26/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9500 - loss: 0.1452 - val_accuracy: 0.9510 - val_loss: 0.1714\n",
      "Epoch 27/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9479 - loss: 0.1525 - val_accuracy: 0.9510 - val_loss: 0.1698\n",
      "Epoch 28/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9386 - loss: 0.1662 - val_accuracy: 0.9510 - val_loss: 0.1693\n",
      "Epoch 29/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9359 - loss: 0.1817 - val_accuracy: 0.9510 - val_loss: 0.1700\n",
      "Epoch 30/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9572 - loss: 0.1433 - val_accuracy: 0.9440 - val_loss: 0.1750\n",
      "Epoch 31/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9449 - loss: 0.1649 - val_accuracy: 0.9510 - val_loss: 0.1695\n",
      "Epoch 32/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9414 - loss: 0.1647 - val_accuracy: 0.9510 - val_loss: 0.1709\n",
      "Epoch 33/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9424 - loss: 0.1614 - val_accuracy: 0.9510 - val_loss: 0.1711\n",
      "Epoch 34/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9399 - loss: 0.1649 - val_accuracy: 0.9510 - val_loss: 0.1705\n",
      "Epoch 35/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9505 - loss: 0.1472 - val_accuracy: 0.9510 - val_loss: 0.1723\n",
      "Epoch 36/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9487 - loss: 0.1497 - val_accuracy: 0.9457 - val_loss: 0.1734\n",
      "Epoch 37/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9535 - loss: 0.1324 - val_accuracy: 0.9527 - val_loss: 0.1720\n",
      "Epoch 38/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9478 - loss: 0.1421 - val_accuracy: 0.9492 - val_loss: 0.1732\n",
      "Epoch 39/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9413 - loss: 0.1581 - val_accuracy: 0.9510 - val_loss: 0.1738\n",
      "Epoch 40/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9545 - loss: 0.1366 - val_accuracy: 0.9492 - val_loss: 0.1752\n",
      "Epoch 41/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9520 - loss: 0.1362 - val_accuracy: 0.9440 - val_loss: 0.1804\n",
      "Epoch 42/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9486 - loss: 0.1480 - val_accuracy: 0.9510 - val_loss: 0.1765\n",
      "Epoch 43/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9522 - loss: 0.1348 - val_accuracy: 0.9475 - val_loss: 0.1780\n",
      "Epoch 44/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9520 - loss: 0.1374 - val_accuracy: 0.9510 - val_loss: 0.1767\n",
      "Epoch 45/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9502 - loss: 0.1341 - val_accuracy: 0.9422 - val_loss: 0.1808\n",
      "Epoch 46/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9520 - loss: 0.1376 - val_accuracy: 0.9475 - val_loss: 0.1798\n",
      "Epoch 47/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9499 - loss: 0.1435 - val_accuracy: 0.9475 - val_loss: 0.1799\n",
      "Epoch 48/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9431 - loss: 0.1482 - val_accuracy: 0.9475 - val_loss: 0.1785\n",
      "Epoch 49/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9445 - loss: 0.1461 - val_accuracy: 0.9510 - val_loss: 0.1783\n",
      "Epoch 50/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9583 - loss: 0.1194 - val_accuracy: 0.9510 - val_loss: 0.1818\n"
     ]
    }
   ],
   "source": [
    "# Model Deep Learning\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))  # binary classification\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs=50, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5095266f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9529 - loss: 0.1663 \n",
      "Akurasi: 0.9467787146568298\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97       674\n",
      "           1       0.75      0.07      0.14        40\n",
      "\n",
      "    accuracy                           0.95       714\n",
      "   macro avg       0.85      0.54      0.55       714\n",
      "weighted avg       0.94      0.95      0.93       714\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluasi\n",
    "loss, acc = model.evaluate(X_test, y_test)\n",
    "print(\"Akurasi:\", acc)\n",
    "\n",
    "# Prediksi dan laporan\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = (y_pred > 0.5).astype(\"int32\")\n",
    "print(classification_report(y_test, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15cd11f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lenovo\\Downloads\\capstone\\.venv\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8891 - loss: 0.4281 - val_accuracy: 0.9510 - val_loss: 0.2664\n",
      "Epoch 2/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9346 - loss: 0.2742 - val_accuracy: 0.9510 - val_loss: 0.2089\n",
      "Epoch 3/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9425 - loss: 0.2193 - val_accuracy: 0.9510 - val_loss: 0.1919\n",
      "Epoch 4/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9349 - loss: 0.2158 - val_accuracy: 0.9510 - val_loss: 0.1840\n",
      "Epoch 5/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9504 - loss: 0.1756 - val_accuracy: 0.9510 - val_loss: 0.1810\n",
      "Epoch 6/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9520 - loss: 0.1675 - val_accuracy: 0.9510 - val_loss: 0.1794\n",
      "Epoch 7/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9425 - loss: 0.1870 - val_accuracy: 0.9510 - val_loss: 0.1782\n",
      "Epoch 8/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9438 - loss: 0.1770 - val_accuracy: 0.9510 - val_loss: 0.1765\n",
      "Epoch 9/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9480 - loss: 0.1707 - val_accuracy: 0.9510 - val_loss: 0.1757\n",
      "Epoch 10/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9434 - loss: 0.1720 - val_accuracy: 0.9510 - val_loss: 0.1748\n",
      "Epoch 11/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9473 - loss: 0.1727 - val_accuracy: 0.9510 - val_loss: 0.1741\n",
      "Epoch 12/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9460 - loss: 0.1668 - val_accuracy: 0.9510 - val_loss: 0.1735\n",
      "Epoch 13/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9376 - loss: 0.1901 - val_accuracy: 0.9510 - val_loss: 0.1726\n",
      "Epoch 14/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9381 - loss: 0.1827 - val_accuracy: 0.9510 - val_loss: 0.1717\n",
      "Epoch 15/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9374 - loss: 0.1912 - val_accuracy: 0.9510 - val_loss: 0.1713\n",
      "Epoch 16/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9485 - loss: 0.1688 - val_accuracy: 0.9510 - val_loss: 0.1713\n",
      "Epoch 17/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9290 - loss: 0.2092 - val_accuracy: 0.9510 - val_loss: 0.1697\n",
      "Epoch 18/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9454 - loss: 0.1671 - val_accuracy: 0.9510 - val_loss: 0.1700\n",
      "Epoch 19/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9400 - loss: 0.1762 - val_accuracy: 0.9510 - val_loss: 0.1703\n",
      "Epoch 20/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9412 - loss: 0.1733 - val_accuracy: 0.9510 - val_loss: 0.1703\n",
      "Epoch 21/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9438 - loss: 0.1689 - val_accuracy: 0.9510 - val_loss: 0.1698\n",
      "Epoch 22/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9444 - loss: 0.1693 - val_accuracy: 0.9510 - val_loss: 0.1703\n",
      "Epoch 23/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9417 - loss: 0.1777 - val_accuracy: 0.9510 - val_loss: 0.1702\n",
      "Epoch 24/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9356 - loss: 0.1911 - val_accuracy: 0.9510 - val_loss: 0.1696\n",
      "Epoch 25/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9461 - loss: 0.1599 - val_accuracy: 0.9510 - val_loss: 0.1690\n",
      "Epoch 26/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9389 - loss: 0.1766 - val_accuracy: 0.9510 - val_loss: 0.1697\n",
      "Epoch 27/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9448 - loss: 0.1665 - val_accuracy: 0.9510 - val_loss: 0.1695\n",
      "Epoch 28/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9498 - loss: 0.1526 - val_accuracy: 0.9510 - val_loss: 0.1694\n",
      "Epoch 29/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9446 - loss: 0.1735 - val_accuracy: 0.9510 - val_loss: 0.1695\n",
      "Epoch 30/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9482 - loss: 0.1615 - val_accuracy: 0.9510 - val_loss: 0.1698\n",
      "Epoch 31/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9396 - loss: 0.1816 - val_accuracy: 0.9510 - val_loss: 0.1689\n",
      "Epoch 32/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9409 - loss: 0.1693 - val_accuracy: 0.9510 - val_loss: 0.1693\n",
      "Epoch 33/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9442 - loss: 0.1633 - val_accuracy: 0.9510 - val_loss: 0.1684\n",
      "Epoch 34/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9387 - loss: 0.1744 - val_accuracy: 0.9510 - val_loss: 0.1690\n",
      "Epoch 35/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9419 - loss: 0.1706 - val_accuracy: 0.9510 - val_loss: 0.1690\n",
      "Epoch 36/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9453 - loss: 0.1666 - val_accuracy: 0.9510 - val_loss: 0.1692\n",
      "Epoch 37/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9394 - loss: 0.1775 - val_accuracy: 0.9510 - val_loss: 0.1689\n",
      "Epoch 38/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9435 - loss: 0.1759 - val_accuracy: 0.9510 - val_loss: 0.1687\n",
      "Epoch 39/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9456 - loss: 0.1669 - val_accuracy: 0.9492 - val_loss: 0.1691\n",
      "Epoch 40/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9474 - loss: 0.1660 - val_accuracy: 0.9510 - val_loss: 0.1693\n",
      "Epoch 41/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9496 - loss: 0.1558 - val_accuracy: 0.9510 - val_loss: 0.1692\n",
      "Epoch 42/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9497 - loss: 0.1572 - val_accuracy: 0.9510 - val_loss: 0.1690\n",
      "Epoch 43/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9389 - loss: 0.1748 - val_accuracy: 0.9492 - val_loss: 0.1688\n",
      "Epoch 44/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9449 - loss: 0.1728 - val_accuracy: 0.9510 - val_loss: 0.1687\n",
      "Epoch 45/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9451 - loss: 0.1606 - val_accuracy: 0.9510 - val_loss: 0.1689\n",
      "Epoch 46/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9364 - loss: 0.1911 - val_accuracy: 0.9510 - val_loss: 0.1683\n",
      "Epoch 47/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9405 - loss: 0.1791 - val_accuracy: 0.9492 - val_loss: 0.1687\n",
      "Epoch 48/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9369 - loss: 0.1800 - val_accuracy: 0.9492 - val_loss: 0.1687\n",
      "Epoch 49/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9494 - loss: 0.1577 - val_accuracy: 0.9475 - val_loss: 0.1693\n",
      "Epoch 50/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9510 - loss: 0.1561 - val_accuracy: 0.9492 - val_loss: 0.1686\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x169d5d70760>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Dense(32, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model2.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model2.fit(X_train, y_train, epochs=50, validation_split=0.2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
